# 需求文档

## 文档说明

### 1  目的

本文档是 Prompt Injection Attack Evaluation 系统即 PiaEval 系统的需求规格说明文档，描述了 PiaEval 系统的功能需求和非功能需求。

本文档的目的是支持开发人员更好地进行系统开发工作。后续的文档编写和代码编写都以本文档为基础。

### 2  范围

PiaEval 系统是为评估大语言模型 LLM 在提示注入攻击 PIA 方面的安全性的评估系统，其主要目的是为 LLM PIA 提供自动化评估的支持。

PiaEval 系统的主要功能包括：LLM 交互、PIA 衡量指标、PIA 基准测试、PIA 自动化评估。

通过 PiaEval 系统的应用，LLM 能够完成 PIA 评估，支持多方面和多层次的评估，轻松完成自动化评估，并对评估结果进行多维对比分析。

### 3  词汇表

| EN Abbr        | English Full Name                         | 中文全称             | 中文简称     | 备注 |
| -------------- | ----------------------------------------- | -------------------- | ------------ | ---- |
| PiaEval System | Prompt Injection Attack Evaluation System | 提示注入攻击评估系统 | Pia 评估系统 | /    |
| LLM            | Large Language Model                      | 大语言模型           | /            | /    |
| PIA            | Prompt Injection Attack                   | 提示注入攻击         | /            | /    |
| SF             | System Feature                            | 系统特性（系统功能） | /            | /    |
| Con            | Constraint                                | 约束                 | /            | /    |
| SR             | System Requirement                        | 系统需求             | /            | /    |

### 4  参考文献

## 总体需求

### 1  市场环境

随着自然语言处理 NLP 技术的发展和 Transformer 架构的出现，大语言模型 LLM 在计算机领域得到了快速发展。从 Google 的 Bert 和 OpenAI 的 ChatGPT 开始，涌现了许多 LLM 开发企业及其开发的 LLM 系统，如 LLaMa、Claude、Qwen、DeepSeek。LLM 不仅在学术研究上具有广阔的研究前景，在商业市场上也得到了一定的应用，出现了许多投入实际生产的 LLM 驱动系统。

随着 LLM 的迅猛发展，对其进行技术监管和法律监管必须同步进行。因而，在专业研究方面，需要 LLM 的一套衡量标准和评估方法。然而，当前对于 LLM 的评估大部分聚焦于其能力和性能方面，对于其它方面的评估则尚不完善。市场对于 LLM 非功能性评估的需求越来越迫切。

考虑到以上方面，本系统选择 LLM 的一个非功能性方面进行评估，即提示注入攻击 PIA 的安全性。本系统将 PIA 分为不同方面、不同层次的类型，对于每种类型的 PIA 设计衡量指标和提供评估方法，并达到对于 PIA 安全性的多方面、多层次的评估。本系统将基准测试和评估流程进行封装，支持用户进行自定义的自动化评估。本系统还将提供典型 LLM 模型的评估结果，以及对被评估 LLM 的评估结果的分析，使得用户能够对评估结果进行多维对比分析。最终，本系统将对 LLM PIA 评估提供一套完整的自动化评估解决方案。

### 2  用户特征

#### LLM 开发者

LLM 开发者希望通过使用本系统评估它们开发的 LLM 在 PIA 安全性方面的技术表现。这一用户群体规模较小，并且每个用户通常只评估一个 LLM 或一个产品系列的 LLM。LLM 开发者可能开发 LLM 本身，也可能开发 LLM 驱动的系统，但通常使用 LLM 本身进行评估。LLM 开发者可能为个人开发者或企业开发者，但通常情况下都是后者。LLM 开发者通常具有一定的技术基础，他们不需要图形化操作界面，更倾向于以接口调用的形式进行工作。LLM 开发者不会阅读本系统的源代码，而是阅读接口文档和技术手册。LLM 开发者更关注其在 PIA 安全性方面的技术要求，而对法律要求不够重视。

#### 法律监管人员

法律监管人员是 LLM 系统的商业产品的监管人员，希望通过使用本系统评估作为商业产品的 LLM 在 PIA 安全性方面的法律表现。这一用户群体规模较大，分布于不同地区和不同层次，并且每个用户会面对许多不同的 LLM 系统。法律监管人员通常只使用 LLM 驱动的系统，没有能力也不希望使用 LLM本身。法律监管人员通常不是计算机领域的专业人员，没有 LLM 开发及评估的技术基础，需要使用图形化操作界面进行工作。法律监管人员没有能力对专业评估结果进行分析，它们需要本系统生成一般人员能够理解的评估报告。法律监管人员更关注其在 PIA 安全性方面的法律要求，而不关心技术要求。

#### LLM 评估系统开发者

可能会有其它 LLM 评估系统的开发者使用本系统。这些开发者可能会阅读源代码、提出修改意见、学习本系统。本系统的目标用户群体不包括他们，但愿意为他们提供一定的支持和帮助。与其它用户群体不同，他们通常会阅读源代码，其次阅读相关文档和使用手册，而并不真正使用本系统。他们对于代码可读性的要求较高，可能还会关注开发过程。这一群体可能会提出宝贵的修改意见，对于它们开发的 LLM 评估系统的参考对于本系统的发展也有所帮助。

### 3  业务需求

### 4  产品功能

SF1：LLM 交互。

SF2：PIA 分类。

SF3：PIA 衡量指标计算。

SF4：PIA 基准测试。

SF5：PIA 自动化评估。

SF6：结果分析和评估报告生成。

SF7：Web 界面。

SF8：使用配置文件进行自动化配置。

SF9：用户。

### 5  开发约束

Con 1：本系统运行在 Windows 11 操作系统上。

Con 2：本系统需要 Python 环境和 Vue 环境，并需要安装相关依赖。

Con 3：本系统实现为客户端-服务端系统，客户端系统使用 Web 页面。

Con 4：本系统使用迭代开发方式进行开发。

Con 5：本系统为个人开发。

### 6  假设依赖

## 详细需求

### 1  外部接口

#### 1.1  接口调用

#### 1.2  配置文件

#### 1.3  前后端接口

#### 1.4  Web 页面

### 2  功能需求

#### SF1 LLM 交互

LLM 交互既能在系统内部完成，也能允许用户通过接口调用的方式完成。后端系统和前端系统均能完成 LLM 交互。支持不同 LLM 的交互，既支持单轮对话，也支持多轮对话。相关配置数据保存在配置文件中，系统应能完成自动化配置，允许静态修改配置文件。支持可选特性，在 LLM 交互时进行监测。

SR1-1：LLM 单轮对话。
SR1-2：LLM 多轮对话。
SR1-3：LLM Web 交互。
SR1-4：LLM 外部接口交互。
SR1-5：LLM 自动化配置。
SR1-6：LLM 交互监测。

#### SF2 PIA 分类

#### SF3  PIA 衡量指标计算

#### SF4  PIA 基准测试

#### SF5  PIA 自动化评估

#### SF6  结果分析和评估报告生成

#### SF7  Web 界面

#### SF8  使用配置文件进行自动化配置

本系统配置数据保存在 json 配置文件中。配置数据如 LLM 配置数据、数据文件路径、网络配置数据等。系统应能自动读取配置文件并完成配置。用户可以静态修改配置文件，但不允许动态修改配置文件。

SR8-1：配置文件。
SR8-2：自动化配置。
SR8-3：静态修改配置。

#### SF9  用户

本系统支持以不同用户身份使用。鉴别用户的依据是账号，这意味着一个现实用户可以有多个虚拟用户。用户注册没有限制，未来考虑使用手机号码或邮箱限制注册。每个用户可以拥有自己的数据，只能访问自己的数据，支持用户数据持久化保存。

SR9-1：用户注册与登录。
SR9-2：用户注册限制。
SR9-3：用户数据隔离与持久化保存。

### 3  性能需求

### 4  约束依赖

### 5  质量属性

### 6  数据需求

#### 6.1  配置文件

#### 6.2  评估数据

#### 6.3  用户数据

### 7  其它需求

## 附录

## 索引